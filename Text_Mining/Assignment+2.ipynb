{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255028"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20742"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16887"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized))\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08133224587104161"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    #len(nltk.word_tokenize(moby_raw))/len(moby)\n",
    "    ratio = example_two()/example_one()\n",
    "    print()\n",
    "    return ratio# Your answer here\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 18707 samples and 255006 outcomes>\n",
      "1086\n",
      "0.004258723324157079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this one should have been easy. But we I converted everyting to lowercase wo that 'whale' and\\n'Whale' would be the same thing. I started to just get a count from that list and jus tuse a for\\nloop to get out every occurance of 'whale'. I decided lets see if there are any tools I \\ncan use in this library. I forgor about the frequency ditribution function.\\nWhen I tried ot use it at first it didn't work. I thought I had the right module imported\\nbut turns out in needed 'from nltk.book import *'. Online I saw I could use  'from nltk.probability import FreqDist'\\nbut assumed that importing nltk would work, it didn't. We use FreqDist to get the \\nfrequency of each token and use dist['whale'] to get the number of 'whale' tokens. \\nThat was just for me to see. It's not necesary for this. The next like 'dist.freq('Whale')\\nis where I print the frequency of the word and the line that we also need to return\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    \n",
    "    moby_raw_lemmetized = nltk.word_tokenize(moby_raw.lower())\n",
    "  \n",
    "    dist = FreqDist(moby_raw_lemmetized)\n",
    "    print(dist)\n",
    "    print(dist['whale'])\n",
    "    print(dist.freq('whale'))\n",
    "   \n",
    "    return dist.freq('whale')# Your answer here\n",
    "\n",
    "answer_two()\n",
    "\n",
    "'''this one should have been easy. But once I converted everyting to lowercase  'whale' and\n",
    "'Whale' would be the same thing. I started to just get a count from that list and jus tuse a for\n",
    "loop to get out every occurance of 'whale'. I decided lets see if there are any tools I \n",
    "can use in this library. I forgor about the frequency ditribution function.\n",
    "When I tried ot use it at first it didn't work. I thought I had the right module imported\n",
    "but turns out in needed 'from nltk.book import *'. Online I saw I could use  'from nltk.probability import FreqDist'\n",
    "but assumed that importing nltk would work, it didn't. We use FreqDist to get the \n",
    "frequency of each token and use dist['whale'] to get the number of 'whale' tokens. \n",
    "That was just for me to see. It's not necesary for this. The next like 'dist.freq('Whale')\n",
    "is where I print the frequency of the word and the line that we also need to return'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 19204), ('the', 14422), ('.', 7284), ('of', 6586), ('and', 6414), ('a', 4698), ('to', 4597), (';', 4173), ('in', 4163), ('that', 3081), ('his', 2530), ('it', 2508), ('i', 2101), ('he', 1890), ('but', 1813), ('!', 1767), ('is', 1748), ('as', 1741), ('with', 1722), ('--', 1713)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I pretty much jsut grabe the first two lines form the previous seciton'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    moby_raw_lemmetized = nltk.word_tokenize(moby_raw.lower())\n",
    "  \n",
    "    dist = FreqDist(moby_raw_lemmetized)\n",
    "    print(dist.most_common(20))\n",
    "    \n",
    "    return dist.most_common(20)# Your answer here\n",
    "\n",
    "answer_three()\n",
    "'''I pretty much just grab the first two lines form the previous seciton. \n",
    "Then I had to do a bit of googling as any developer would if they don't know. \n",
    "I came accross the most_common funciton which pretty much returns exactly what I needed.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['almost', 'before', 'captain', 'chapter', 'himself', 'little', 'pequod', 'queequeg', 'seemed', 'should', 'starbuck', 'though', 'through', 'whales', 'without']\n"
     ]
    }
   ],
   "source": [
    "def answer_four():\n",
    "    moby_raw_lemmetized = nltk.word_tokenize(moby_raw.lower())\n",
    "    dist = FreqDist(moby_raw_lemmetized)\n",
    "    \n",
    "    freqwords = [w for w in dist if len(w) > 5 and dist[w] > 150]\n",
    "    \n",
    "    print(sorted(freqwords))\n",
    "    return # Your answer here\n",
    "\n",
    "answer_four()\n",
    "'''I use those smae beginning two lines to get the distribution then \n",
    "I pretty much just copied and what was in the video. They practically \n",
    "gave us the answer for this one'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Moby Dick by Herman Melville 1851>\n",
      "twelve-o'clock-at-night\n"
     ]
    }
   ],
   "source": [
    "def answer_five():\n",
    "    print(text1)\n",
    "    longest_word = max(text1,key=len)\n",
    "    print(longest_word)\n",
    "    \n",
    "    return longest_word# Your answer here\n",
    "\n",
    "answer_five()\n",
    "\n",
    "'''This one I was feeling particularly lazy. The word it returned was twelve-o'clock-at-night'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 19204), ('the', 14422), ('.', 7284), ('of', 6586), ('and', 6414), ('a', 4698), ('to', 4597), (';', 4173), ('in', 4163), ('that', 3081), ('his', 2530), ('it', 2508), ('i', 2101), ('he', 1890), ('but', 1813), ('!', 1767), ('is', 1748), ('as', 1741), ('with', 1722), ('--', 1713)]\n",
      "<class 'nltk.probability.FreqDist'>\n",
      "[('the', 14422), ('of', 6586), ('and', 6414), ('a', 4698), ('to', 4597), ('in', 4163), ('that', 3081), ('his', 2530), ('it', 2508), ('i', 2101)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm assuming they want tokens here unlike what I did at top\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    moby_raw_lemmetized = nltk.word_tokenize(moby_raw.lower())\n",
    "    dist = FreqDist(moby_raw_lemmetized)\n",
    "    print(dist.most_common(20))\n",
    "    print(type(dist))\n",
    "    \n",
    "    freqwords = [w for w in dist if dist[w] > 2000 and w.isalpha()]\n",
    "    \n",
    "    large_freq_words = []\n",
    "    for w in dist:\n",
    "        if dist[w]>2000 and w.isalpha():\n",
    "            large_freq_words.append((w,dist[w])) \n",
    "    large_freq_words.sort(key=lambda x:x[1],reverse = True)\n",
    "    print(large_freq_words)\n",
    "    return # Your answer here\n",
    "\n",
    "answer_six()\n",
    "'''I'm assuming they want tokens here unlike what I did at top. Then I pretty much just used a for loop.\n",
    "I createda list of tuples with the word and the frequency. I found the sorted function which sorts by\n",
    "the tuples second value and \"reverse=True\" sots in decending order'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.962736713500306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'First I use the sen_tokenize to get the sentences.  I just grabed the length of all the sentences and the the number of sentences \\nand I simply get the average. \\nYou can see I get the total number of tokens by just tallying up the lenght of each sentence.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    sentences = nltk.sent_tokenize(moby_raw.lower())\n",
    "    tot = 0\n",
    "    #print(list(sentences))\n",
    "    for sent in list(sentences):\n",
    "        token_sent = nltk.word_tokenize(sent)\n",
    "       # print(token_sent)\n",
    "        tot = tot+len(token_sent)\n",
    "    \n",
    "    avg = tot/len(sentences)\n",
    "    print(avg)\n",
    "    return # Your answer here\n",
    "\n",
    "answer_seven()\n",
    "'''First I use the sen_tokenize to get the sentences.  \n",
    "Then for each sentence I tokenize it to get the number of words in each sentence.\n",
    "In the for loop I just start tallying up the number of words and after the for loop I simply\n",
    "divide the total number of tokens by the the number of senctences. \n",
    "There may be a better way of doing htis by simply using the nltk library but I didn't look\n",
    "up a way using that solution.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 32727), ('IN', 28662), ('DT', 25879), (',', 19204), ('JJ', 17613)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The first two line Ijust pull formt the example in the module2 notebook'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    tokenized_word = nltk.word_tokenize(moby_raw)\n",
    "    pos_tags = nltk.pos_tag(tokenized_word)\n",
    "    #print(pos_tags)\n",
    "    tags = [tag for (word,tag) in pos_tags]\n",
    "    pos_freq = nltk.FreqDist(tags)\n",
    "    print(pos_freq.most_common(5))\n",
    "    #for pos_of_s in pos_tags:\n",
    "        \n",
    "    return # Your answer here\n",
    "\n",
    "answer_eight()\n",
    "\n",
    "''' The first two lines I just pull from the example in the module2 notebook. \n",
    "I pretty much get the POS for each tag. Then I needed some help. stack overflow pretty much gave\n",
    "me this answer. But, for each tuple in pos_tags we store the tag. Then We use the FreqDist to \n",
    "grab the most frequent tags. We can then use the most_common function to grab the \n",
    "top five most common tags'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.util import ngrams\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "  \n",
    "\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpulent', 'indecence', 'validate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I had to look up what Ngrams are whcih are these...\\nN-grams are continuous sequences of words or symbols or tokens in a document. The answer to this one is almost quite\\nliterallyon Geeks4Geeks here https://www.geeksforgeeks.org/correcting-words-using-nltk-in-python/. \\nI didn't really know what any of it meant until after doing some research. \\nFirst the ofr loop grabs the first incorrect word, \\nthen we check the first letters of the incorrect and correct word in lists \\nand if they are the same  we use that as a weight for the first value in the \\njaccard_sidtance function. The jaccard_distance funciton just calculates the distance of the \\ncorrect and incorect word word with each correct spelling. \\nWe sort them so that the shortest distance is on top and append that to the list of correctly spelled words.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    correct_entries =  []\n",
    "    for word in entries:\n",
    "        temp = [(jaccard_distance(set(ngrams(word, 3)),\n",
    "                              set(ngrams(w, 3))),w)\n",
    "                for w in correct_spellings if w[0]==word[0]]\n",
    "        correct_entries.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "    print(correct_entries)\n",
    "    \n",
    "    return correct_entries# Your answer here\n",
    "    \n",
    "answer_nine()\n",
    "\n",
    "'''I had to look up what Ngrams are whcih are these...\n",
    "N-grams are continuous sequences of words or symbols or tokens in a document. The answer to this one is almost quite\n",
    "literallyon Geeks4Geeks here https://www.geeksforgeeks.org/correcting-words-using-nltk-in-python/. \n",
    "I didn't really know what any of it meant until after doing some research. \n",
    "First the ofr loop grabs the first incorrect word, \n",
    "then we check the first letters of the incorrect and correct word in lists \n",
    "and if they are the same  we use the \n",
    "jaccard_sidtance function. The jaccard_distance funciton just calculates the distance of the \n",
    "correct and incorect word word with each correct spelling. \n",
    "We sort them so that the shortest distance is on top and append that to the list of correctly spelled words.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cormus', 'incendiary', 'valid']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0, 'v'),\n",
       " (1.0, 'vaagmer'),\n",
       " (1.0, 'vaalite'),\n",
       " (1.0, 'vacabond'),\n",
       " (1.0, 'vacancy'),\n",
       " (1.0, 'vacant'),\n",
       " (1.0, 'vacanthearted'),\n",
       " (1.0, 'vacantheartedness'),\n",
       " (1.0, 'vacantly'),\n",
       " (1.0, 'vacantness'),\n",
       " (1.0, 'vacantry'),\n",
       " (1.0, 'vacatable'),\n",
       " (1.0, 'vacate'),\n",
       " (1.0, 'vacation'),\n",
       " (1.0, 'vacational'),\n",
       " (1.0, 'vacationer'),\n",
       " (1.0, 'vacationist'),\n",
       " (1.0, 'vacationless'),\n",
       " (1.0, 'vacatur'),\n",
       " (1.0, 'vaccary'),\n",
       " (1.0, 'vaccenic'),\n",
       " (1.0, 'vaccicide'),\n",
       " (1.0, 'vaccigenous'),\n",
       " (1.0, 'vaccina'),\n",
       " (1.0, 'vaccinable'),\n",
       " (1.0, 'vaccinal'),\n",
       " (1.0, 'vaccinate'),\n",
       " (1.0, 'vaccination'),\n",
       " (1.0, 'vaccinationist'),\n",
       " (1.0, 'vaccinator'),\n",
       " (1.0, 'vaccinatory'),\n",
       " (1.0, 'vaccine'),\n",
       " (1.0, 'vaccinee'),\n",
       " (1.0, 'vaccinella'),\n",
       " (1.0, 'vaccinia'),\n",
       " (1.0, 'vacciniaceous'),\n",
       " (1.0, 'vaccinial'),\n",
       " (1.0, 'vaccinifer'),\n",
       " (1.0, 'vacciniform'),\n",
       " (1.0, 'vacciniola'),\n",
       " (1.0, 'vaccinist'),\n",
       " (1.0, 'vaccinium'),\n",
       " (1.0, 'vaccinization'),\n",
       " (1.0, 'vaccinogenic'),\n",
       " (1.0, 'vaccinogenous'),\n",
       " (1.0, 'vaccinoid'),\n",
       " (1.0, 'vaccinophobia'),\n",
       " (1.0, 'vaccinotherapy'),\n",
       " (1.0, 'vache'),\n",
       " (1.0, 'vachette'),\n",
       " (1.0, 'vacillancy'),\n",
       " (1.0, 'vacillant'),\n",
       " (1.0, 'vacillate'),\n",
       " (1.0, 'vacillating'),\n",
       " (1.0, 'vacillatingly'),\n",
       " (1.0, 'vacillation'),\n",
       " (1.0, 'vacillator'),\n",
       " (1.0, 'vacillatory'),\n",
       " (1.0, 'vacoa'),\n",
       " (1.0, 'vacona'),\n",
       " (1.0, 'vacoua'),\n",
       " (1.0, 'vacouf'),\n",
       " (1.0, 'vacual'),\n",
       " (1.0, 'vacuate'),\n",
       " (1.0, 'vacuation'),\n",
       " (1.0, 'vacuefy'),\n",
       " (1.0, 'vacuist'),\n",
       " (1.0, 'vacuity'),\n",
       " (1.0, 'vacuolar'),\n",
       " (1.0, 'vacuolary'),\n",
       " (1.0, 'vacuolate'),\n",
       " (1.0, 'vacuolated'),\n",
       " (1.0, 'vacuolation'),\n",
       " (1.0, 'vacuole'),\n",
       " (1.0, 'vacuolization'),\n",
       " (1.0, 'vacuome'),\n",
       " (1.0, 'vacuometer'),\n",
       " (1.0, 'vacuous'),\n",
       " (1.0, 'vacuously'),\n",
       " (1.0, 'vacuousness'),\n",
       " (1.0, 'vacuum'),\n",
       " (1.0, 'vacuuma'),\n",
       " (1.0, 'vacuumize'),\n",
       " (1.0, 'vade'),\n",
       " (1.0, 'vadimonium'),\n",
       " (1.0, 'vadimony'),\n",
       " (1.0, 'vadium'),\n",
       " (1.0, 'vadose'),\n",
       " (1.0, 'vady'),\n",
       " (1.0, 'vag'),\n",
       " (1.0, 'vagabond'),\n",
       " (1.0, 'vagabondage'),\n",
       " (1.0, 'vagabondager'),\n",
       " (1.0, 'vagabondia'),\n",
       " (1.0, 'vagabondish'),\n",
       " (1.0, 'vagabondism'),\n",
       " (1.0, 'vagabondismus'),\n",
       " (1.0, 'vagabondize'),\n",
       " (1.0, 'vagabondizer'),\n",
       " (1.0, 'vagabondry'),\n",
       " (1.0, 'vagal'),\n",
       " (1.0, 'vagarian'),\n",
       " (1.0, 'vagarious'),\n",
       " (1.0, 'vagariously'),\n",
       " (1.0, 'vagarish'),\n",
       " (1.0, 'vagarisome'),\n",
       " (1.0, 'vagarist'),\n",
       " (1.0, 'vagaristic'),\n",
       " (1.0, 'vagarity'),\n",
       " (1.0, 'vagary'),\n",
       " (1.0, 'vagas'),\n",
       " (1.0, 'vage'),\n",
       " (1.0, 'vagiform'),\n",
       " (1.0, 'vagile'),\n",
       " (1.0, 'vagina'),\n",
       " (1.0, 'vaginal'),\n",
       " (1.0, 'vaginalectomy'),\n",
       " (1.0, 'vaginaless'),\n",
       " (1.0, 'vaginalitis'),\n",
       " (1.0, 'vaginant'),\n",
       " (1.0, 'vaginate'),\n",
       " (1.0, 'vaginated'),\n",
       " (1.0, 'vaginectomy'),\n",
       " (1.0, 'vaginervose'),\n",
       " (1.0, 'vaginicoline'),\n",
       " (1.0, 'vaginicolous'),\n",
       " (1.0, 'vaginiferous'),\n",
       " (1.0, 'vaginipennate'),\n",
       " (1.0, 'vaginismus'),\n",
       " (1.0, 'vaginitis'),\n",
       " (1.0, 'vaginoabdominal'),\n",
       " (1.0, 'vaginocele'),\n",
       " (1.0, 'vaginodynia'),\n",
       " (1.0, 'vaginofixation'),\n",
       " (1.0, 'vaginolabial'),\n",
       " (1.0, 'vaginometer'),\n",
       " (1.0, 'vaginomycosis'),\n",
       " (1.0, 'vaginoperineal'),\n",
       " (1.0, 'vaginoperitoneal'),\n",
       " (1.0, 'vaginopexy'),\n",
       " (1.0, 'vaginoplasty'),\n",
       " (1.0, 'vaginoscope'),\n",
       " (1.0, 'vaginoscopy'),\n",
       " (1.0, 'vaginotome'),\n",
       " (1.0, 'vaginotomy'),\n",
       " (1.0, 'vaginovesical'),\n",
       " (1.0, 'vaginovulvar'),\n",
       " (1.0, 'vaginula'),\n",
       " (1.0, 'vaginulate'),\n",
       " (1.0, 'vaginule'),\n",
       " (1.0, 'vagitus'),\n",
       " (1.0, 'vagoaccessorius'),\n",
       " (1.0, 'vagodepressor'),\n",
       " (1.0, 'vagoglossopharyngeal'),\n",
       " (1.0, 'vagogram'),\n",
       " (1.0, 'vagolysis'),\n",
       " (1.0, 'vagosympathetic'),\n",
       " (1.0, 'vagotomize'),\n",
       " (1.0, 'vagotomy'),\n",
       " (1.0, 'vagotonia'),\n",
       " (1.0, 'vagotonic'),\n",
       " (1.0, 'vagotropic'),\n",
       " (1.0, 'vagotropism'),\n",
       " (1.0, 'vagrance'),\n",
       " (1.0, 'vagrancy'),\n",
       " (1.0, 'vagrant'),\n",
       " (1.0, 'vagrantism'),\n",
       " (1.0, 'vagrantize'),\n",
       " (1.0, 'vagrantlike'),\n",
       " (1.0, 'vagrantly'),\n",
       " (1.0, 'vagrantness'),\n",
       " (0.8888888888888888, 'vagrate'),\n",
       " (1.0, 'vagrom'),\n",
       " (1.0, 'vague'),\n",
       " (1.0, 'vaguely'),\n",
       " (1.0, 'vagueness'),\n",
       " (1.0, 'vaguish'),\n",
       " (1.0, 'vaguity'),\n",
       " (1.0, 'vagulous'),\n",
       " (1.0, 'vagus'),\n",
       " (1.0, 'vahine'),\n",
       " (1.0, 'vail'),\n",
       " (1.0, 'vailable'),\n",
       " (1.0, 'vain'),\n",
       " (1.0, 'vainful'),\n",
       " (1.0, 'vainglorious'),\n",
       " (1.0, 'vaingloriously'),\n",
       " (1.0, 'vaingloriousness'),\n",
       " (1.0, 'vainglory'),\n",
       " (1.0, 'vainly'),\n",
       " (1.0, 'vainness'),\n",
       " (1.0, 'vair'),\n",
       " (1.0, 'vairagi'),\n",
       " (1.0, 'vaire'),\n",
       " (1.0, 'vairy'),\n",
       " (1.0, 'vaivode'),\n",
       " (1.0, 'vajra'),\n",
       " (1.0, 'vajrasana'),\n",
       " (1.0, 'vakass'),\n",
       " (1.0, 'vakia'),\n",
       " (1.0, 'vakil'),\n",
       " (1.0, 'vakkaliga'),\n",
       " (1.0, 'valance'),\n",
       " (1.0, 'valanced'),\n",
       " (1.0, 'valanche'),\n",
       " (1.0, 'valbellite'),\n",
       " (1.0, 'vale'),\n",
       " (1.0, 'valediction'),\n",
       " (1.0, 'valedictorian'),\n",
       " (1.0, 'valedictorily'),\n",
       " (1.0, 'valedictory'),\n",
       " (1.0, 'valence'),\n",
       " (1.0, 'valencianite'),\n",
       " (1.0, 'valency'),\n",
       " (1.0, 'valent'),\n",
       " (1.0, 'valentine'),\n",
       " (1.0, 'valentinite'),\n",
       " (1.0, 'valeral'),\n",
       " (1.0, 'valeraldehyde'),\n",
       " (1.0, 'valeramide'),\n",
       " (0.9, 'valerate'),\n",
       " (1.0, 'valerian'),\n",
       " (1.0, 'valerianaceous'),\n",
       " (1.0, 'valerianate'),\n",
       " (1.0, 'valeric'),\n",
       " (1.0, 'valerin'),\n",
       " (1.0, 'valerolactone'),\n",
       " (1.0, 'valerone'),\n",
       " (1.0, 'valeryl'),\n",
       " (1.0, 'valerylene'),\n",
       " (1.0, 'valet'),\n",
       " (1.0, 'valeta'),\n",
       " (1.0, 'valetage'),\n",
       " (1.0, 'valetdom'),\n",
       " (1.0, 'valethood'),\n",
       " (1.0, 'valetism'),\n",
       " (1.0, 'valetry'),\n",
       " (1.0, 'valetudinarian'),\n",
       " (1.0, 'valetudinarianism'),\n",
       " (1.0, 'valetudinariness'),\n",
       " (1.0, 'valetudinarist'),\n",
       " (1.0, 'valetudinarium'),\n",
       " (1.0, 'valetudinary'),\n",
       " (1.0, 'valeur'),\n",
       " (1.0, 'valeward'),\n",
       " (1.0, 'valgoid'),\n",
       " (1.0, 'valgus'),\n",
       " (1.0, 'valhall'),\n",
       " (0.8333333333333334, 'vali'),\n",
       " (0.9, 'valiance'),\n",
       " (0.9, 'valiancy'),\n",
       " (0.8888888888888888, 'valiant'),\n",
       " (0.9090909090909091, 'valiantly'),\n",
       " (0.9230769230769231, 'valiantness'),\n",
       " (0.6666666666666666, 'valid'),\n",
       " (0.7777777777777778, 'validate'),\n",
       " (0.8181818181818182, 'validation'),\n",
       " (0.8181818181818182, 'validatory'),\n",
       " (0.8666666666666667, 'validification'),\n",
       " (0.7777777777777778, 'validity'),\n",
       " (0.75, 'validly'),\n",
       " (0.8, 'validness'),\n",
       " (0.875, 'valine'),\n",
       " (0.875, 'valise'),\n",
       " (0.9090909090909091, 'valiseful'),\n",
       " (0.9, 'valiship'),\n",
       " (1.0, 'vall'),\n",
       " (1.0, 'vallancy'),\n",
       " (1.0, 'vallar'),\n",
       " (1.0, 'vallary'),\n",
       " (1.0, 'vallate'),\n",
       " (1.0, 'vallated'),\n",
       " (1.0, 'vallation'),\n",
       " (1.0, 'vallecula'),\n",
       " (1.0, 'vallecular'),\n",
       " (1.0, 'valleculate'),\n",
       " (1.0, 'vallevarite'),\n",
       " (1.0, 'valley'),\n",
       " (1.0, 'valleyful'),\n",
       " (1.0, 'valleyite'),\n",
       " (1.0, 'valleylet'),\n",
       " (1.0, 'valleylike'),\n",
       " (1.0, 'valleyward'),\n",
       " (1.0, 'valleywise'),\n",
       " (1.0, 'vallicula'),\n",
       " (1.0, 'vallicular'),\n",
       " (1.0, 'vallidom'),\n",
       " (1.0, 'vallis'),\n",
       " (1.0, 'vallisneriaceous'),\n",
       " (1.0, 'vallum'),\n",
       " (1.0, 'valonia'),\n",
       " (1.0, 'valoniaceous'),\n",
       " (1.0, 'valor'),\n",
       " (1.0, 'valorization'),\n",
       " (1.0, 'valorize'),\n",
       " (1.0, 'valorous'),\n",
       " (1.0, 'valorously'),\n",
       " (1.0, 'valorousness'),\n",
       " (1.0, 'valse'),\n",
       " (1.0, 'valsoid'),\n",
       " (1.0, 'valuable'),\n",
       " (1.0, 'valuableness'),\n",
       " (1.0, 'valuably'),\n",
       " (1.0, 'valuate'),\n",
       " (1.0, 'valuation'),\n",
       " (1.0, 'valuational'),\n",
       " (1.0, 'valuator'),\n",
       " (1.0, 'value'),\n",
       " (1.0, 'valued'),\n",
       " (1.0, 'valueless'),\n",
       " (1.0, 'valuelessness'),\n",
       " (1.0, 'valuer'),\n",
       " (1.0, 'valuta'),\n",
       " (1.0, 'valva'),\n",
       " (1.0, 'valval'),\n",
       " (1.0, 'valvate'),\n",
       " (1.0, 'valve'),\n",
       " (1.0, 'valved'),\n",
       " (1.0, 'valveless'),\n",
       " (1.0, 'valvelet'),\n",
       " (1.0, 'valvelike'),\n",
       " (1.0, 'valveman'),\n",
       " (1.0, 'valviferous'),\n",
       " (1.0, 'valviform'),\n",
       " (1.0, 'valvotomy'),\n",
       " (1.0, 'valvula'),\n",
       " (1.0, 'valvular'),\n",
       " (1.0, 'valvulate'),\n",
       " (1.0, 'valvule'),\n",
       " (1.0, 'valvulitis'),\n",
       " (1.0, 'valvulotome'),\n",
       " (1.0, 'valvulotomy'),\n",
       " (1.0, 'valyl'),\n",
       " (1.0, 'valylene'),\n",
       " (1.0, 'vambrace'),\n",
       " (1.0, 'vambraced'),\n",
       " (1.0, 'vamfont'),\n",
       " (1.0, 'vammazsa'),\n",
       " (1.0, 'vamoose'),\n",
       " (1.0, 'vamp'),\n",
       " (1.0, 'vamped'),\n",
       " (1.0, 'vamper'),\n",
       " (1.0, 'vamphorn'),\n",
       " (1.0, 'vampire'),\n",
       " (1.0, 'vampireproof'),\n",
       " (1.0, 'vampiric'),\n",
       " (1.0, 'vampirish'),\n",
       " (1.0, 'vampirism'),\n",
       " (1.0, 'vampirize'),\n",
       " (1.0, 'vamplate'),\n",
       " (1.0, 'vampproof'),\n",
       " (1.0, 'van'),\n",
       " (1.0, 'vanadate'),\n",
       " (1.0, 'vanadiate'),\n",
       " (1.0, 'vanadic'),\n",
       " (1.0, 'vanadiferous'),\n",
       " (1.0, 'vanadinite'),\n",
       " (1.0, 'vanadium'),\n",
       " (1.0, 'vanadosilicate'),\n",
       " (1.0, 'vanadous'),\n",
       " (1.0, 'vanadyl'),\n",
       " (1.0, 'vanaprastha'),\n",
       " (1.0, 'vancourier'),\n",
       " (1.0, 'vandalish'),\n",
       " (1.0, 'vandalism'),\n",
       " (1.0, 'vandalistic'),\n",
       " (1.0, 'vandalization'),\n",
       " (1.0, 'vandalize'),\n",
       " (1.0, 'vandalroot'),\n",
       " (1.0, 'vane'),\n",
       " (1.0, 'vaned'),\n",
       " (1.0, 'vaneless'),\n",
       " (1.0, 'vanelike'),\n",
       " (1.0, 'vanessian'),\n",
       " (1.0, 'vanfoss'),\n",
       " (1.0, 'vang'),\n",
       " (1.0, 'vangee'),\n",
       " (1.0, 'vangeli'),\n",
       " (1.0, 'vanglo'),\n",
       " (1.0, 'vanguard'),\n",
       " (1.0, 'vanilla'),\n",
       " (1.0, 'vanillal'),\n",
       " (1.0, 'vanillaldehyde'),\n",
       " (1.0, 'vanillate'),\n",
       " (1.0, 'vanille'),\n",
       " (1.0, 'vanillery'),\n",
       " (1.0, 'vanillic'),\n",
       " (1.0, 'vanillin'),\n",
       " (1.0, 'vanillinic'),\n",
       " (1.0, 'vanillism'),\n",
       " (1.0, 'vanilloes'),\n",
       " (1.0, 'vanillon'),\n",
       " (1.0, 'vanilloyl'),\n",
       " (1.0, 'vanillyl'),\n",
       " (1.0, 'vanish'),\n",
       " (1.0, 'vanisher'),\n",
       " (1.0, 'vanishing'),\n",
       " (1.0, 'vanishingly'),\n",
       " (1.0, 'vanishment'),\n",
       " (1.0, 'vanitarianism'),\n",
       " (1.0, 'vanitied'),\n",
       " (1.0, 'vanity'),\n",
       " (1.0, 'vanjarrah'),\n",
       " (1.0, 'vanman'),\n",
       " (1.0, 'vanmost'),\n",
       " (1.0, 'vanner'),\n",
       " (1.0, 'vannerman'),\n",
       " (1.0, 'vannet'),\n",
       " (1.0, 'vanquish'),\n",
       " (1.0, 'vanquishable'),\n",
       " (1.0, 'vanquisher'),\n",
       " (1.0, 'vanquishment'),\n",
       " (1.0, 'vansire'),\n",
       " (1.0, 'vantage'),\n",
       " (1.0, 'vantageless'),\n",
       " (1.0, 'vantbrace'),\n",
       " (1.0, 'vantbrass'),\n",
       " (1.0, 'vanward'),\n",
       " (1.0, 'vapid'),\n",
       " (1.0, 'vapidism'),\n",
       " (1.0, 'vapidity'),\n",
       " (1.0, 'vapidly'),\n",
       " (1.0, 'vapidness'),\n",
       " (1.0, 'vapocauterization'),\n",
       " (1.0, 'vapographic'),\n",
       " (1.0, 'vapography'),\n",
       " (1.0, 'vapor'),\n",
       " (1.0, 'vaporability'),\n",
       " (1.0, 'vaporable'),\n",
       " (1.0, 'vaporarium'),\n",
       " (1.0, 'vaporary'),\n",
       " (0.9, 'vaporate'),\n",
       " (1.0, 'vapored'),\n",
       " (1.0, 'vaporer'),\n",
       " (1.0, 'vaporescence'),\n",
       " (1.0, 'vaporescent'),\n",
       " (1.0, 'vaporiferous'),\n",
       " (1.0, 'vaporiferousness'),\n",
       " (1.0, 'vaporific'),\n",
       " (1.0, 'vaporiform'),\n",
       " (1.0, 'vaporimeter'),\n",
       " (1.0, 'vaporing'),\n",
       " (1.0, 'vaporingly'),\n",
       " (1.0, 'vaporish'),\n",
       " (1.0, 'vaporishness'),\n",
       " (1.0, 'vaporium'),\n",
       " (1.0, 'vaporizable'),\n",
       " (1.0, 'vaporization'),\n",
       " (1.0, 'vaporize'),\n",
       " (1.0, 'vaporizer'),\n",
       " (1.0, 'vaporless'),\n",
       " (1.0, 'vaporlike'),\n",
       " (1.0, 'vaporograph'),\n",
       " (1.0, 'vaporographic'),\n",
       " (1.0, 'vaporose'),\n",
       " (1.0, 'vaporoseness'),\n",
       " (1.0, 'vaporosity'),\n",
       " (1.0, 'vaporous'),\n",
       " (1.0, 'vaporously'),\n",
       " (1.0, 'vaporousness'),\n",
       " (1.0, 'vaportight'),\n",
       " (1.0, 'vapory'),\n",
       " (1.0, 'vapulary'),\n",
       " (1.0, 'vapulate'),\n",
       " (1.0, 'vapulation'),\n",
       " (1.0, 'vapulatory'),\n",
       " (1.0, 'vara'),\n",
       " (1.0, 'varahan'),\n",
       " (1.0, 'varan'),\n",
       " (1.0, 'varanid'),\n",
       " (1.0, 'vardapet'),\n",
       " (1.0, 'vardy'),\n",
       " (1.0, 'vare'),\n",
       " (1.0, 'varec'),\n",
       " (1.0, 'vareheaded'),\n",
       " (1.0, 'vareuse'),\n",
       " (1.0, 'vargueno'),\n",
       " (1.0, 'vari'),\n",
       " (1.0, 'variability'),\n",
       " (1.0, 'variable'),\n",
       " (1.0, 'variableness'),\n",
       " (1.0, 'variably'),\n",
       " (1.0, 'variance'),\n",
       " (1.0, 'variancy'),\n",
       " (1.0, 'variant'),\n",
       " (1.0, 'variate'),\n",
       " (1.0, 'variation'),\n",
       " (1.0, 'variational'),\n",
       " (1.0, 'variationist'),\n",
       " (1.0, 'variatious'),\n",
       " (1.0, 'variative'),\n",
       " (1.0, 'variatively'),\n",
       " (1.0, 'variator'),\n",
       " (1.0, 'varical'),\n",
       " (1.0, 'varicated'),\n",
       " (1.0, 'varication'),\n",
       " (1.0, 'varicella'),\n",
       " (1.0, 'varicellar'),\n",
       " (1.0, 'varicellate'),\n",
       " (1.0, 'varicellation'),\n",
       " (1.0, 'varicelliform'),\n",
       " (1.0, 'varicelloid'),\n",
       " (1.0, 'varicellous'),\n",
       " (1.0, 'varices'),\n",
       " (1.0, 'variciform'),\n",
       " (1.0, 'varicoblepharon'),\n",
       " (1.0, 'varicocele'),\n",
       " (1.0, 'varicoid'),\n",
       " (1.0, 'varicolored'),\n",
       " (1.0, 'varicolorous'),\n",
       " (1.0, 'varicose'),\n",
       " (1.0, 'varicosed'),\n",
       " (1.0, 'varicoseness'),\n",
       " (1.0, 'varicosis'),\n",
       " (1.0, 'varicosity'),\n",
       " (1.0, 'varicotomy'),\n",
       " (1.0, 'varicula'),\n",
       " (1.0, 'varied'),\n",
       " (1.0, 'variedly'),\n",
       " (1.0, 'variegate'),\n",
       " (1.0, 'variegated'),\n",
       " (1.0, 'variegation'),\n",
       " (1.0, 'variegator'),\n",
       " (1.0, 'varier'),\n",
       " (1.0, 'varietal'),\n",
       " (1.0, 'varietally'),\n",
       " (1.0, 'varietism'),\n",
       " (1.0, 'varietist'),\n",
       " (1.0, 'variety'),\n",
       " (1.0, 'variform'),\n",
       " (1.0, 'variformed'),\n",
       " (1.0, 'variformity'),\n",
       " (1.0, 'variformly'),\n",
       " (1.0, 'varigradation'),\n",
       " (1.0, 'variocoupler'),\n",
       " (1.0, 'variola'),\n",
       " (1.0, 'variolar'),\n",
       " (1.0, 'variolate'),\n",
       " (1.0, 'variolation'),\n",
       " (1.0, 'variole'),\n",
       " (1.0, 'variolic'),\n",
       " (1.0, 'varioliform'),\n",
       " (1.0, 'variolite'),\n",
       " (1.0, 'variolitic'),\n",
       " (1.0, 'variolitization'),\n",
       " (1.0, 'variolization'),\n",
       " (1.0, 'varioloid'),\n",
       " (1.0, 'variolous'),\n",
       " (1.0, 'variolovaccine'),\n",
       " (1.0, 'variolovaccinia'),\n",
       " (1.0, 'variometer'),\n",
       " (1.0, 'variorum'),\n",
       " (1.0, 'variotinted'),\n",
       " (1.0, 'various'),\n",
       " (1.0, 'variously'),\n",
       " (1.0, 'variousness'),\n",
       " (1.0, 'variscite'),\n",
       " (1.0, 'varisse'),\n",
       " (1.0, 'varix'),\n",
       " (1.0, 'varlet'),\n",
       " (1.0, 'varletaille'),\n",
       " (1.0, 'varletess'),\n",
       " (1.0, 'varletry'),\n",
       " (1.0, 'varletto'),\n",
       " (1.0, 'varment'),\n",
       " (1.0, 'varna'),\n",
       " (1.0, 'varnashrama'),\n",
       " (1.0, 'varnish'),\n",
       " (1.0, 'varnished'),\n",
       " (1.0, 'varnisher'),\n",
       " (1.0, 'varnishing'),\n",
       " (1.0, 'varnishlike'),\n",
       " (1.0, 'varnishment'),\n",
       " (1.0, 'varnishy'),\n",
       " (1.0, 'varnpliktige'),\n",
       " (1.0, 'varnsingite'),\n",
       " (1.0, 'varsha'),\n",
       " (1.0, 'varsity'),\n",
       " (1.0, 'varsoviana'),\n",
       " (1.0, 'varus'),\n",
       " (1.0, 'varve'),\n",
       " (1.0, 'varved'),\n",
       " (1.0, 'vary'),\n",
       " (1.0, 'varyingly'),\n",
       " (1.0, 'vas'),\n",
       " (1.0, 'vasa'),\n",
       " (1.0, 'vasal'),\n",
       " (1.0, 'vascular'),\n",
       " (1.0, 'vascularity'),\n",
       " (1.0, 'vascularization'),\n",
       " (1.0, 'vascularize'),\n",
       " (1.0, 'vascularly'),\n",
       " (1.0, 'vasculated'),\n",
       " (1.0, 'vasculature'),\n",
       " (1.0, 'vasculiferous'),\n",
       " (1.0, 'vasculiform'),\n",
       " (1.0, 'vasculitis'),\n",
       " (1.0, 'vasculogenesis'),\n",
       " (1.0, 'vasculolymphatic'),\n",
       " (1.0, 'vasculomotor'),\n",
       " (1.0, 'vasculose'),\n",
       " (1.0, 'vasculum'),\n",
       " (1.0, 'vase'),\n",
       " (1.0, 'vasectomize'),\n",
       " (1.0, 'vasectomy'),\n",
       " (1.0, 'vaseful'),\n",
       " (1.0, 'vaselet'),\n",
       " (1.0, 'vaselike'),\n",
       " (1.0, 'vasemaker'),\n",
       " (1.0, 'vasemaking'),\n",
       " (1.0, 'vasewise'),\n",
       " (1.0, 'vasework'),\n",
       " (1.0, 'vashegyite'),\n",
       " (1.0, 'vasicentric'),\n",
       " (1.0, 'vasicine'),\n",
       " (1.0, 'vasifactive'),\n",
       " (1.0, 'vasiferous'),\n",
       " (1.0, 'vasiform'),\n",
       " (1.0, 'vasoconstricting'),\n",
       " (1.0, 'vasoconstriction'),\n",
       " (1.0, 'vasoconstrictive'),\n",
       " (1.0, 'vasoconstrictor'),\n",
       " (1.0, 'vasocorona'),\n",
       " (1.0, 'vasodentinal'),\n",
       " (1.0, 'vasodentine'),\n",
       " (1.0, 'vasodilatation'),\n",
       " (1.0, 'vasodilatin'),\n",
       " (1.0, 'vasodilating'),\n",
       " (1.0, 'vasodilation'),\n",
       " (1.0, 'vasodilator'),\n",
       " (1.0, 'vasoepididymostomy'),\n",
       " (1.0, 'vasofactive'),\n",
       " (1.0, 'vasoformative'),\n",
       " (1.0, 'vasoganglion'),\n",
       " (1.0, 'vasohypertonic'),\n",
       " (1.0, 'vasohypotonic'),\n",
       " (1.0, 'vasoinhibitor'),\n",
       " (1.0, 'vasoinhibitory'),\n",
       " (1.0, 'vasoligation'),\n",
       " (1.0, 'vasoligature'),\n",
       " (1.0, 'vasomotion'),\n",
       " (1.0, 'vasomotor'),\n",
       " (1.0, 'vasomotorial'),\n",
       " (1.0, 'vasomotoric'),\n",
       " (1.0, 'vasomotory'),\n",
       " (1.0, 'vasoneurosis'),\n",
       " (1.0, 'vasoparesis'),\n",
       " (1.0, 'vasopressor'),\n",
       " (1.0, 'vasopuncture'),\n",
       " (1.0, 'vasoreflex'),\n",
       " (1.0, 'vasorrhaphy'),\n",
       " (1.0, 'vasosection'),\n",
       " (1.0, 'vasospasm'),\n",
       " (1.0, 'vasospastic'),\n",
       " (1.0, 'vasostimulant'),\n",
       " (1.0, 'vasostomy'),\n",
       " (1.0, 'vasotomy'),\n",
       " (1.0, 'vasotonic'),\n",
       " (1.0, 'vasotribe'),\n",
       " (1.0, 'vasotripsy'),\n",
       " (1.0, 'vasotrophic'),\n",
       " (1.0, 'vasovesiculectomy'),\n",
       " (1.0, 'vasquine'),\n",
       " (1.0, 'vassal'),\n",
       " (1.0, 'vassalage'),\n",
       " (1.0, 'vassaldom'),\n",
       " (1.0, 'vassaless'),\n",
       " (1.0, 'vassalic'),\n",
       " (1.0, 'vassalism'),\n",
       " (1.0, 'vassality'),\n",
       " (1.0, 'vassalize'),\n",
       " (1.0, 'vassalless'),\n",
       " (1.0, 'vassalry'),\n",
       " (1.0, 'vassalship'),\n",
       " (1.0, 'vast'),\n",
       " (1.0, 'vastate'),\n",
       " (1.0, 'vastation'),\n",
       " (1.0, 'vastidity'),\n",
       " (1.0, 'vastily'),\n",
       " (1.0, 'vastiness'),\n",
       " (1.0, 'vastitude'),\n",
       " (1.0, 'vastity'),\n",
       " (1.0, 'vastly'),\n",
       " (1.0, 'vastness'),\n",
       " (1.0, 'vasty'),\n",
       " (1.0, 'vasu'),\n",
       " (1.0, 'vat'),\n",
       " (1.0, 'vatful'),\n",
       " (1.0, 'vatic'),\n",
       " (1.0, 'vatically'),\n",
       " (1.0, 'vaticanal'),\n",
       " (1.0, 'vaticanic'),\n",
       " (1.0, 'vaticanical'),\n",
       " (1.0, 'vaticide'),\n",
       " (1.0, 'vaticinal'),\n",
       " (1.0, 'vaticinant'),\n",
       " (1.0, 'vaticinate'),\n",
       " (1.0, 'vaticination'),\n",
       " (1.0, 'vaticinator'),\n",
       " (1.0, 'vaticinatory'),\n",
       " (1.0, 'vaticinatress'),\n",
       " (1.0, 'vaticinatrix'),\n",
       " (1.0, 'vatmaker'),\n",
       " (1.0, 'vatmaking'),\n",
       " (1.0, 'vatman'),\n",
       " (1.0, 'vatter'),\n",
       " (1.0, 'vau'),\n",
       " (1.0, 'vaucheriaceous'),\n",
       " (1.0, 'vaudeville'),\n",
       " (1.0, 'vaudevillian'),\n",
       " (1.0, 'vaudevillist'),\n",
       " (1.0, 'vaudy'),\n",
       " (1.0, 'vaugnerite'),\n",
       " (1.0, 'vault'),\n",
       " (1.0, 'vaulted'),\n",
       " (1.0, 'vaultedly'),\n",
       " (1.0, 'vaulter'),\n",
       " (1.0, 'vaulting'),\n",
       " (1.0, 'vaultlike'),\n",
       " (1.0, 'vaulty'),\n",
       " (1.0, 'vaunt'),\n",
       " (1.0, 'vauntage'),\n",
       " (1.0, 'vaunted'),\n",
       " (1.0, 'vaunter'),\n",
       " (1.0, 'vauntery'),\n",
       " (1.0, 'vauntful'),\n",
       " (1.0, 'vauntiness'),\n",
       " (1.0, 'vaunting'),\n",
       " (1.0, 'vauntingly'),\n",
       " (1.0, 'vauntmure'),\n",
       " (1.0, 'vaunty'),\n",
       " (1.0, 'vauquelinite'),\n",
       " (1.0, 'vauxite'),\n",
       " (1.0, 'vavasor'),\n",
       " (1.0, 'vavasory'),\n",
       " (1.0, 'vaward'),\n",
       " (1.0, 'veal'),\n",
       " (1.0, 'vealer'),\n",
       " (1.0, 'vealiness'),\n",
       " (1.0, 'veallike'),\n",
       " (1.0, 'vealskin'),\n",
       " (1.0, 'vealy'),\n",
       " (1.0, 'vectigal'),\n",
       " (1.0, 'vection'),\n",
       " (1.0, 'vectis'),\n",
       " (1.0, 'vectograph'),\n",
       " (1.0, 'vectographic'),\n",
       " (1.0, 'vector'),\n",
       " (1.0, 'vectorial'),\n",
       " (1.0, 'vectorially'),\n",
       " (1.0, 'vecture'),\n",
       " (1.0, 'vedana'),\n",
       " (1.0, 'vedette'),\n",
       " (1.0, 'vedika'),\n",
       " (1.0, 'vedro'),\n",
       " (1.0, 'veduis'),\n",
       " (1.0, 'vee'),\n",
       " (1.0, 'veen'),\n",
       " (1.0, 'veep'),\n",
       " (1.0, 'veer'),\n",
       " (1.0, 'veerable'),\n",
       " (1.0, 'veeringly'),\n",
       " (1.0, 'veery'),\n",
       " (1.0, 'vegasite'),\n",
       " (1.0, 'vegeculture'),\n",
       " (1.0, 'vegetability'),\n",
       " (1.0, 'vegetable'),\n",
       " (1.0, 'vegetablelike'),\n",
       " (1.0, 'vegetablewise'),\n",
       " (1.0, 'vegetablize'),\n",
       " (1.0, 'vegetably'),\n",
       " (1.0, 'vegetal'),\n",
       " (1.0, 'vegetalcule'),\n",
       " (1.0, 'vegetality'),\n",
       " (1.0, 'vegetant'),\n",
       " (1.0, 'vegetarian'),\n",
       " (1.0, 'vegetarianism'),\n",
       " (1.0, 'vegetate'),\n",
       " (1.0, 'vegetation'),\n",
       " (1.0, 'vegetational'),\n",
       " (1.0, 'vegetationless'),\n",
       " (1.0, 'vegetative'),\n",
       " (1.0, 'vegetatively'),\n",
       " (1.0, 'vegetativeness'),\n",
       " (1.0, 'vegete'),\n",
       " (1.0, 'vegeteness'),\n",
       " (1.0, 'vegetism'),\n",
       " (1.0, 'vegetive'),\n",
       " (1.0, 'vegetivorous'),\n",
       " (1.0, 'vegetoalkali'),\n",
       " (1.0, 'vegetoalkaline'),\n",
       " (1.0, 'vegetoalkaloid'),\n",
       " (1.0, 'vegetoanimal'),\n",
       " (1.0, 'vegetobituminous'),\n",
       " (1.0, 'vegetocarbonaceous'),\n",
       " (1.0, 'vegetomineral'),\n",
       " (1.0, 'vehemence'),\n",
       " (1.0, 'vehemency'),\n",
       " (1.0, 'vehement'),\n",
       " (1.0, 'vehemently'),\n",
       " (1.0, 'vehicle'),\n",
       " (1.0, 'vehicular'),\n",
       " (1.0, 'vehicularly'),\n",
       " (1.0, 'vehiculary'),\n",
       " (1.0, 'vehiculate'),\n",
       " (1.0, 'vehiculation'),\n",
       " (1.0, 'vehiculatory'),\n",
       " (1.0, 'vei'),\n",
       " (1.0, 'veigle'),\n",
       " (1.0, 'veil'),\n",
       " (1.0, 'veiled'),\n",
       " (1.0, 'veiledly'),\n",
       " (1.0, 'veiledness'),\n",
       " (1.0, 'veiler'),\n",
       " (1.0, 'veiling'),\n",
       " (1.0, 'veilless'),\n",
       " (1.0, 'veillike'),\n",
       " (1.0, 'veilmaker'),\n",
       " (1.0, 'veilmaking'),\n",
       " (1.0, 'veily'),\n",
       " (1.0, 'vein'),\n",
       " (1.0, 'veinage'),\n",
       " (1.0, 'veinal'),\n",
       " (1.0, 'veinbanding'),\n",
       " (1.0, 'veined'),\n",
       " (1.0, 'veiner'),\n",
       " (1.0, 'veinery'),\n",
       " (1.0, 'veininess'),\n",
       " (1.0, 'veining'),\n",
       " (1.0, 'veinless'),\n",
       " (1.0, 'veinlet'),\n",
       " (1.0, 'veinous'),\n",
       " (1.0, 'veinstone'),\n",
       " (1.0, 'veinstuff'),\n",
       " (1.0, 'veinule'),\n",
       " (1.0, 'veinulet'),\n",
       " (1.0, 'veinwise'),\n",
       " (1.0, 'veinwork'),\n",
       " (1.0, 'veiny'),\n",
       " (1.0, 'vejoces'),\n",
       " (1.0, 'vela'),\n",
       " (1.0, 'velal'),\n",
       " (1.0, 'velamen'),\n",
       " (1.0, 'velamentous'),\n",
       " (1.0, 'velamentum'),\n",
       " (1.0, 'velar'),\n",
       " (1.0, 'velardenite'),\n",
       " (1.0, 'velaric'),\n",
       " (1.0, 'velarium'),\n",
       " (1.0, 'velarize'),\n",
       " (1.0, 'velary'),\n",
       " (1.0, 'velate'),\n",
       " (1.0, 'velated'),\n",
       " (1.0, 'velation'),\n",
       " (1.0, 'velatura'),\n",
       " (1.0, 'veldcraft'),\n",
       " (1.0, 'veldman'),\n",
       " (1.0, 'veldschoen'),\n",
       " (1.0, 'veldt'),\n",
       " (1.0, 'veldtschoen'),\n",
       " (1.0, 'velellidous'),\n",
       " (1.0, 'velic'),\n",
       " (1.0, 'veliferous'),\n",
       " (1.0, 'veliform'),\n",
       " (1.0, 'veliger'),\n",
       " (1.0, 'veligerous'),\n",
       " (1.0, 'velitation'),\n",
       " (1.0, 'vell'),\n",
       " (1.0, 'vellala'),\n",
       " (1.0, 'velleda'),\n",
       " (1.0, 'velleity'),\n",
       " (1.0, 'vellicate'),\n",
       " (1.0, 'vellication'),\n",
       " (1.0, 'vellicative'),\n",
       " (1.0, 'vellinch'),\n",
       " (1.0, 'vellon'),\n",
       " (1.0, 'vellosine'),\n",
       " (1.0, 'velloziaceous'),\n",
       " (1.0, 'vellum'),\n",
       " (1.0, 'vellumy'),\n",
       " (1.0, 'velo'),\n",
       " (1.0, 'velociman'),\n",
       " (1.0, 'velocimeter'),\n",
       " (1.0, 'velocious'),\n",
       " (1.0, 'velociously'),\n",
       " (1.0, 'velocipedal'),\n",
       " (1.0, 'velocipede'),\n",
       " (1.0, 'velocipedean'),\n",
       " (1.0, 'velocipedic'),\n",
       " (1.0, 'velocitous'),\n",
       " (1.0, 'velocity'),\n",
       " (1.0, 'velodrome'),\n",
       " (1.0, 'velometer'),\n",
       " (1.0, 'velours'),\n",
       " (1.0, 'veloutine'),\n",
       " (1.0, 'velte'),\n",
       " (1.0, 'velum'),\n",
       " (1.0, 'velumen'),\n",
       " (1.0, 'velure'),\n",
       " (1.0, 'velutinous'),\n",
       " (1.0, 'velveret'),\n",
       " (1.0, 'velvet'),\n",
       " (1.0, 'velvetbreast'),\n",
       " (1.0, 'velveted'),\n",
       " (1.0, 'velveteen'),\n",
       " (1.0, 'velveteened'),\n",
       " (1.0, 'velvetiness'),\n",
       " (1.0, 'velveting'),\n",
       " (1.0, 'velvetleaf'),\n",
       " (1.0, 'velvetlike'),\n",
       " (1.0, 'velvetry'),\n",
       " (1.0, 'velvetseed'),\n",
       " (1.0, 'velvetweed'),\n",
       " (1.0, 'velvetwork'),\n",
       " (1.0, 'velvety'),\n",
       " (1.0, 'venada'),\n",
       " (1.0, 'venal'),\n",
       " (1.0, 'venality'),\n",
       " (1.0, 'venalization'),\n",
       " (1.0, 'venalize'),\n",
       " (1.0, 'venally'),\n",
       " (1.0, 'venalness'),\n",
       " (1.0, 'venanzite'),\n",
       " (1.0, 'venatic'),\n",
       " (1.0, 'venatical'),\n",
       " (1.0, 'venatically'),\n",
       " (1.0, 'venation'),\n",
       " (1.0, 'venational'),\n",
       " (1.0, 'venator'),\n",
       " (1.0, 'venatorial'),\n",
       " (1.0, 'venatorious'),\n",
       " (1.0, 'venatory'),\n",
       " (1.0, 'vencola'),\n",
       " (1.0, 'vend'),\n",
       " (1.0, 'vendace'),\n",
       " (1.0, 'vendee'),\n",
       " (1.0, 'vender'),\n",
       " (1.0, 'vendetta'),\n",
       " (1.0, 'vendettist'),\n",
       " (1.0, 'vendibility'),\n",
       " (1.0, 'vendible'),\n",
       " (1.0, 'vendibleness'),\n",
       " (1.0, 'vendibly'),\n",
       " (1.0, 'vendicate'),\n",
       " (1.0, 'vending'),\n",
       " (1.0, 'venditate'),\n",
       " (1.0, 'venditation'),\n",
       " (1.0, 'vendition'),\n",
       " (1.0, 'venditor'),\n",
       " (1.0, 'vendor'),\n",
       " (1.0, 'vendue'),\n",
       " (1.0, 'veneer'),\n",
       " (1.0, 'veneerer'),\n",
       " (1.0, 'veneering'),\n",
       " (1.0, 'venefical'),\n",
       " (1.0, 'veneficious'),\n",
       " (1.0, 'veneficness'),\n",
       " (1.0, 'veneficous'),\n",
       " (1.0, 'venenate'),\n",
       " (1.0, 'venenation'),\n",
       " (1.0, 'venene'),\n",
       " (1.0, 'veneniferous'),\n",
       " (1.0, 'venenific'),\n",
       " (1.0, 'venenosalivary'),\n",
       " (1.0, 'venenous'),\n",
       " (1.0, 'venenousness'),\n",
       " (1.0, 'venepuncture'),\n",
       " (1.0, 'venerability'),\n",
       " (1.0, 'venerable'),\n",
       " (1.0, 'venerableness'),\n",
       " (1.0, 'venerably'),\n",
       " (1.0, 'veneracean'),\n",
       " (1.0, 'veneraceous'),\n",
       " (1.0, 'veneral'),\n",
       " (1.0, 'venerance'),\n",
       " (1.0, 'venerant'),\n",
       " (0.9, 'venerate'),\n",
       " (1.0, 'veneration'),\n",
       " (1.0, 'venerational'),\n",
       " (1.0, 'venerative'),\n",
       " (1.0, 'veneratively'),\n",
       " (1.0, 'venerativeness'),\n",
       " (1.0, 'venerator'),\n",
       " (1.0, 'venereal'),\n",
       " (1.0, 'venerealness'),\n",
       " (1.0, 'venereologist'),\n",
       " (1.0, 'venereology'),\n",
       " (1.0, 'venerer'),\n",
       " (1.0, 'venerial'),\n",
       " (1.0, 'veneriform'),\n",
       " (1.0, 'venery'),\n",
       " (1.0, 'venesect'),\n",
       " (1.0, 'venesection'),\n",
       " (1.0, 'venesector'),\n",
       " (1.0, 'venesia'),\n",
       " (1.0, 'venezolano'),\n",
       " (1.0, 'vengeable'),\n",
       " (1.0, 'vengeance'),\n",
       " (1.0, 'vengeant'),\n",
       " (1.0, 'vengeful'),\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    correct_entries =  []\n",
    "    for word in entries:\n",
    "        temp = [(jaccard_distance(set(ngrams(word, 4)),\n",
    "                              set(ngrams(w, 4))),w)\n",
    "                for w in correct_spellings if w[0]==word[0]]\n",
    "        correct_entries.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "    print(correct_entries)\n",
    "    \n",
    "    return correct_entries\n",
    "     # Your answer here\n",
    "    \n",
    "answer_ten()\n",
    "'''For this one we do the exact smae thing as we did in number 9. We jsut change the value in the\n",
    "ngrams to 4 sicne we are looking at the 4-grams of words '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corpulent', 'intendence', 'validate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Again this pretty much works the same way as above.Just with a different function. '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    from nltk.metrics.distance  import edit_distance\n",
    "    correct_entries =  []\n",
    "    for word in entries:\n",
    "        temp = [(edit_distance(word, w),w) for w in correct_spellings if w[0]==word[0]]\n",
    "        correct_entries.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "    print(correct_entries)\n",
    "    return correct_entries# Your answer here \n",
    "    \n",
    "answer_eleven()\n",
    "''' Again this pretty much works the same way as above.Just with a different function. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
